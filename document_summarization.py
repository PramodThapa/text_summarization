# -*- coding: utf-8 -*-
"""document_summarization.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aX0jz-M_W8l0rkX3fc9gG7Hq7nYL5Idi
"""

disciple_txt='Human beings are the larger parts of a social framework and for any framework to function, rules and regulations are an absolute necessity. When these regulations guide human behavior and devise a sense of organization, a system or an individual is said to be disciplined. Discipline finds its importance in every aspect of human as well as other forms of life. It instills a sense of responsibility, credibility and nurtures a person to be more accountable for their actions.From the daily routine of a sportsperson, the regular schedule of a businessperson to the first steps or achievements of children, discipline is present in all places. But it is equally important to understand that the same book of rules does not work for every person. Punishments may work brilliantly for one child in school but make another child feel miserable about themselves. So discipline anywhere should be compatible and considerate. Unlike the “terms and conditions” which suit their own needs, discipline should always be framed to meet individual requirements first.In our fast-paced lives, we often have to run so fast to be a part of the crowd, that we forget our own planned schedules. This leads to sleepless nights, anxiety, disorder and in extreme cases chaos and commotion. We indeed need to keep pushing ourselves to blend with the competition, but putting ourselves first is indispensable.While discipline does have several interpretations and perceptions, its ultimate purpose is to give us a clear idea of life. The history of great personalities is a witness to the power of discipline in driving accomplishments. Discipline doesn’t always have to be something dictating every minute of our life, it can be in the form of small steps which one fine day, bring home a bigger, better version of ourselves.'

#import libaries
import spacy
from spacy.lang.en.stop_words import STOP_WORDS
from string import punctuation

#list the STOPWORDS
#Stopwords are the most common words in any natural language. 
#For the purpose of analyzing text data and building NLP models, these stopwords might not add much value to the meaning of the document.
stopwords=list(STOP_WORDS)
stopwords

nlp=spacy.load('en_core_web_sm')

doc=nlp(disciple_txt)

#identify the tokens in text
# In NLP tokens are either word, characters or sub-words
# First word tokenization
tokens=[token.text for token in doc]
print(tokens)

#add new line symbol to the punctuations
punctuation=punctuation+'/n'
punctuation

#count the frequencies of each word token 
word_frequencies={}
for word in doc:
  if word.text.lower() not in stopwords:
    if word.text.lower() not in punctuation:
      if word.text.lower() not in word_frequencies.keys():
        word_frequencies[word.text]=1
      else:
        word_frequencies[word.text] += 1

print(word_frequencies)

# word with max_frequency
max_frequency=max(word_frequencies.values())
max_frequency

#let's look word with max frequency
max_word_frequency=[]
for word in word_frequencies.keys():
  if word_frequencies[word]==5:
    max_word_frequency.append(word)

max_word_frequency

#normalize the frequency
# divide with value of each token frequency with max_frequnecy 
for word in word_frequencies.keys():
  word_frequencies[word]=word_frequencies[word]/max_frequency

print (word_frequencies)

#sentence_tokenization
sentence_tokens=[sent for sent in doc.sents]
print(sentence_tokens)

#calculate sentence score
# sentence score is the total of each word token frequency in each sentence
sentence_scores={}

for sent in sentence_tokens:
  for word in sent:
    if word.text.lower() in word_frequencies.keys():
      if sent not in sentence_scores.keys():
        sentence_scores[sent]=word_frequencies[word.text.lower()]
      else:
         sentence_scores[sent]+=word_frequencies[word.text.lower()]

sentence_scores

#lets find 40% summarization
from heapq import nlargest
select_length=int(len(sentence_tokens)*0.4)
select_length

summary=nlargest(select_length, sentence_scores,key=sentence_scores.get)

summary

final_summary=[word.text for word in summary]

final_summary

summary=''.join(final_summary)

print (summary)

len(disciple_txt)

len(summary)